# General configuration
crossdata-connector.akka.cluster.seed-nodes = ["akka.tcp://CrossdataServerCluster@127.0.0.1:13420"]
crossdata-connector.akka.remote.netty.tcp.hostname = "127.0.0.1"
crossdata-connector.akka.remote.netty.tcp.port = 0
crossdata-connector.config.connector.name = "SparkSQLConnector"
crossdata-connector.config.akka.number.connector-actor = 5

# Spark cluster configuration
spark.serializer       =org.apache.spark.serializer.KryoSerializer
spark.kryo.registrator =com.stratio.deep.serializer.DeepKryoRegistrator


#SPARK CONFIG FOR LOCAL OR CLUSTER
#spark.master            ="local[*]"
#spark.home             =/opt/spark-1.3.0-bin-hadoop2.4
spark.jars             =[
  ../repo/com/stratio/connector/stratio-connector-sparksql-core/0.3.4/stratio-connector-sparksql-core-0.3.4.jar,
  ../repo/com/stratio/crossdata/crossdata-common/0.5.0/crossdata-common-0.5.0.jar,
  ../repo/com/stratio/connector/stratio-connector-commons-core/0.6.3/stratio-connector-commons-core-0.6.3.jar,
  ../repo/org/apache/spark/spark-hive_2.10/1.4.1/spark-hive_2.10-1.4.1.jar,
  ../repo/com/google/guava/guava/14.0.1/guava-14.0.1.jar,
  ../repo/com/datastax/cassandra/cassandra-driver-core/2.1.5/cassandra-driver-core-2.1.5.jar,
  ../repo/mysql/mysql-connector-java/5.1.34/mysql-connector-java-5.1.34.jar
  ../repo/com/datastax/spark/spark-cassandra-connector_2.10/1.4.0/spark-cassandra-connector_2.10-1.4.0.jar,
  ../repo/com/stratio/spark-mongodb-core/0.8.7/spark-mongodb-core-0.8.7.jar,
  ../repo/org/mongodb/casbah-commons_2.10/2.8.0/casbah-commons_2.10-2.8.0.jar,
  ../repo/org/mongodb/casbah-core_2.10/2.8.0/casbah-core_2.10-2.8.0.jar,
  ../repo/org/mongodb/casbah-query_2.10/2.8.0/casbah-query_2.10-2.8.0.jar,
  ../repo/org/mongodb/mongo-java-driver/2.13.0/mongo-java-driver-2.13.0.jar
]
# SPARK CONFIG FOR MESOS SAMPLE ¡¡¡¡WARNING!!!! REVISE & UPDATE JARS DEPENDENCES
#spark.master           ="mesos://zk://QA-Nodo3-U13.stratio.com:2181,QA-Nodo4-U13.stratio.com:2181,QA-Nodo2-U13.stratio.com:2181/mesos"
#spark.home             =/opt/sds/spark
#spark.jars             =["/opt/sds/connectors/deep/lib/stratio-connector-deep-0.X.X.jar","/opt/sds/connectors/deep/lib/crossdata-common-0.X.X.jar"]

#SPARK CONFIG FOR LOCAL
spark.master ="local[4]"
spark.driver.memory = 512M
spark.executor.memory = 512M
spark.cores.max = 4
spark.akka.heartbeat.interval = 5000

# Connector custom props
connector.sql-context-type = HiveContext #HBaseContext Or SQLContext
connector.query-executors.size  = 5
connector.query-executors.chunk-size = 1000 #rows
connector.count-approx-timeout = 5 #seconds
connector.async-stoppable = true

spark.home             =/opt/sds/spark-1.4.1

# Classes used by the connector in order to use the providers
datastore.providers = ["com.stratio.connector.sparksql.test.TestProvider"]

#spark.hadoop.hbase.zookeeper.quorum = "[IP]"
