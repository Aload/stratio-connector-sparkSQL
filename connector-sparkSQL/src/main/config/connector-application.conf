# General configuration
crossdata-connector.akka.cluster.seed-nodes = ["akka.tcp://CrossdataServerCluster@127.0.0.1:13420"]
crossdata-connector.akka.remote.netty.tcp.hostname = "127.0.0.1"
crossdata-connector.akka.remote.netty.tcp.port = 0
crossdata-connector.config.connector.name = "SparkSQLConnector"
crossdata-connector.config.akka.number.connector-actor = 5

# Spark cluster configuration
spark.serializer       =org.apache.spark.serializer.KryoSerializer
spark.kryo.registrator =com.stratio.deep.serializer.DeepKryoRegistrator

#SPARK CONFIG FOR LOCAL
#spark.master           ="spark://conectores02.stratio.com:7077"
#spark.master            ="spark://jmgomez:7077"
#spark.master             = "spark://ccaballero:7077"
spark.master            ="local[4]"
#spark.home             =/opt/spark-1.3.0-bin-hadoop2.4
spark.jars             =[
  /home/ccaballero/lib/stratio-connector-sparksql-0.1.0-SNAPSHOT.jar,
  /home/ccaballero/lib/crossdata-common-0.3.0-RC2.jar,
  /home/ccaballero/lib/stratio-connector-commons-0.5.0-RC2.jar,
  /home/ccaballero/lib/spark-hive_2.10-1.3.1.jar,
  /home/ccaballero/lib/guava-14.0.1.jar,
  /home/ccaballero/lib/cassandra-driver-core-2.1.5.jar,
  /home/ccaballero/lib/cassandra-thrift-2.1.3.jar,
  /home/ccaballero/lib/mysql-connector-java-5.1.34.jar,
  /home/ccaballero/lib/spark-cassandra-connector_2.10-1.3.0-SNAPSHOT.jar
]
# SPARK CONFIG FOR MESOS SAMPLE ¡¡¡¡WARNING!!!! REVISE & UPDATE JARS DEPENDENCES
#spark.master           ="mesos://zk://QA-Nodo3-U13.stratio.com:2181,QA-Nodo4-U13.stratio.com:2181,QA-Nodo2-U13.stratio.com:2181/mesos"
#spark.home             =/opt/sds/spark
#spark.jars             =["/opt/sds/connectors/deep/lib/stratio-connector-deep-0.X.X.jar","/opt/sds/connectors/deep/lib/crossdata-common-0.X.X.jar"]
spark.driver.memory = 512M
spark.executor.memory = 512M
spark.cores.max = 4
spark.akka.heartbeat.interval = 5000

# SPARK CONFIG FOR Connector-Cluster
#spark.master           ="local[4]"
spark.home             =/var/benchmark/spark
#spark.jars             =[]

# Connector custom props
connector.sql-context-type = HiveContext #HBaseContext Or SQLContext
connector.query-executors.size  = 5
connector.query-executors.chunk-size = 1000 #rows
connector.count-approx-timeout = 5 #seconds
connector.async-stoppable = true
spark.hadoop.hbase.zookeeper.quorum = "conectores02"
