# General configuration
crossdata-connector.akka.cluster.seed-nodes = ["akka.tcp://CrossdataServerCluster@127.0.0.1:13420"]
crossdata-connector.akka.remote.netty.tcp.hostname = "127.0.0.1"
crossdata-connector.akka.remote.netty.tcp.port = 0
crossdata-connector.config.connector.name = "SparkSQLConnector"
crossdata-connector.config.akka.number.connector-actor = 5

# Spark cluster configuration
spark.serializer       =org.apache.spark.serializer.KryoSerializer
spark.kryo.registrator =com.stratio.deep.serializer.DeepKryoRegistrator

#SPARK CONFIG FOR LOCAL OR CLUSTER
#spark.master           ="spark://conectores02.stratio.com:7077"
#spark.master            ="spark://jmgomez:7077"
spark.master             = "spark://conectores02.stratio.com:7077"
#spark.master            ="local[4]"
#spark.home             =/opt/spark-1.3.0-bin-hadoop2.4
spark.jars             =[
  /home/lfernandez/stratio/deep/stratio-connector-sparkSQL/connector-sparkSQL/target/stratio-connector-sparksql-0.1.0-SNAPSHOT.jar,
  /home/lfernandez/stratio/work/crossdata/crossdata-common/target/crossdata-common-0.3.0-RC2-SNAPSHOT.jar,
  /home/lfernandez/stratio/work/stratio-connector-commons/connector-commons/target/stratio-connector-commons-0.5.0-RC2.jar,
  /home/lfernandez/.m2/repository/org/apache/spark/spark-hive_2.10/1.3.1/spark-hive_2.10-1.3.1.jar,
  /home/lfernandez/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar,
  /home/lfernandez/.m2/repository/com/datastax/cassandra/cassandra-driver-core/2.1.5/cassandra-driver-core-2.1.5.jar,
  /home/lfernandez/.m2/repository/org/apache/cassandra/cassandra-thrift/2.1.3/cassandra-thrift-2.1.3.jar,
  /home/lfernandez/.m2/repository/mysql/mysql-connector-java/5.1.34/mysql-connector-java-5.1.34.jar,
  /home/lfernandez/.m2/repository/com/datastax/spark/spark-cassandra-connector_2.10/1.3.0-SNAPSHOT/spark-cassandra-connector_2.10-1.3.0-SNAPSHOT.jar,
  /home/lfernandez/.m2/repository/com/stratio/spark-mongodb/0.8.1/spark-mongodb-0.8.1.jar,
  /home/lfernandez/.m2/repository/org/apache/spark/spark-hbase_2.10/1.3.0/spark-hbase_2.10-1.3.0.jar
]
# SPARK CONFIG FOR MESOS SAMPLE ¡¡¡¡WARNING!!!! REVISE & UPDATE JARS DEPENDENCES
#spark.master           ="mesos://zk://QA-Nodo3-U13.stratio.com:2181,QA-Nodo4-U13.stratio.com:2181,QA-Nodo2-U13.stratio.com:2181/mesos"
#spark.home             =/opt/sds/spark
#spark.jars             =["/opt/sds/connectors/deep/lib/stratio-connector-deep-0.X.X.jar","/opt/sds/connectors/deep/lib/crossdata-common-0.X.X.jar"]

spark.driver.memory = 512M
spark.executor.memory = 512M
spark.cores.max = 4
spark.akka.heartbeat.interval = 5000


spark.home             ="[path]/spark"

# Connector custom props
connector.sql-context-type = HiveContext #HBaseContext Or SQLContext
connector.query-executors.size  = 5
connector.query-executors.chunk-size = 1000 #rows
connector.count-approx-timeout = 5 #seconds
connector.async-stoppable = true
spark.hadoop.hbase.zookeeper.quorum = "conectores02"

